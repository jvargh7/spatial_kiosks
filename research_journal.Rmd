---
title: "Spatial Kiosk Research Journal"
output:
  html_document:
    df_print: paged
---

# 2024-05-07

There are some key issues would like to discuss with the Pursuant team before proceeding with any further analysis. 

1. Missingness (as in complete blanks) are not too high (below 10\%) with the exception of BMI which is at 93%. Height and weight are also missing at high rates. Was under the impression we would have BMI for everyone so want to confirm. 
2. Strange values and mixups for nearly all values (years for gender, gender for ethnicity, etc.). Curious how this can happen in the Pursuant data collection and want to consult them on how to treat these values. They might be able to fix them on their end. 
3. Same thing as #2 but for continuous values. Many implausible BMI, BP, birth year values. Also want to know the precision of the machine to verify whether 100 and 100.01 should be treated as different. Want to confirm with Pursuant how to handle these values. 
4. No data for Massachusetts? I know there are Walmarts

# 2024-05-14

Notes for upcoming data meeting. A basic data cleaning pipeline I imagine with the variables we have would be

1. `birth_year`: Drop if too old (1930 or earlier)
2. `gender`: Drop if missing (not male or female). 
3. `ethnicity`: Drop if missing. This has much higher missingness compared to the other two demographic variables.
4. `bp_systolic`: Drop if outside the range 60-300.
5. `bp_diastolic`: Drop if outside the range 30-300. 
6. `pseudo_member_id`: Identify any members who recorded multiple SBP/DBP reading sessions within the same year. Take the average to represent the year. 

Since session space-time data look reliable, we can limit data cleaning to the above steps. 

One thing to do before any data cleaning is to fix some data organization issues. The key one is about 79,000~ rows of sessions where ethnicity was listed as "male" or "female." I later found that it was because each of the variables had been shifted one column over for some reason. In other words, for these sessions, the variables had been encoded as 

`birth_year <- gender <- ethnicity <- height_inches` 
`bp_systolic <- bp_diastolic <- bp_map` 

So we need to fix that before dropping observations.

## Questions

1. Which questions are mandatory for a session? 
2. Why would gender or ethnicity be missing, but birth year not be missing? Is a blank response a data issue, an incomplete session, or a "unspecified" or "do not wish to respond" kind of response? 
3. How did the variables get shifted for those particular sessions? Could not find any real pattern by space, time, or other characteristics. Is there a possibility this shift could have occurred in other sessions?
4. How would unreasonable SBP and DBP measurements occur? What happens if someone puts the cuff on wrong? Could it be equipment failure? Is Pursuant notified of any equipment failure that is picked up in data recording? Is it possible for SBP/DBP to be collected but not MAP? 
5. Precision of BP measurements? Should it be to the 0.1? Or are those errors.
6. Pursuant's absence in Massachusetts?

## Answers

1. Not relevant
2. Data error. 
3. Data error solved by Cameron in the latest version of the limited dataset. 
4. No way to tell. Just use limits set by Jithin (SBP in 60-300, DBP in 30-300). 
5. Just use as is. 
6. Lawsuit. Will have to make do. 

# 2024-05-24

Steps for data preprocessing.

1. Filter out Old ages.
2. Filter out Unreasonable bp values.
3. Subset by year. 
4. Identify multiple sessions. 
5. Link to supplemental data.
6. Create hypertension indicator.
7. Create population weights. 

# 2024-06-12

For the problem of multiple recorded sessions belonging to the same user, we can really view this as a strength rather than a weakness. We have repeated measurements of BP for certain indidividuals in our dataset. Then within every year, we represent the individual by taking the average of all BP readings. 

# 2024-06-24

We have an issue with the supplemental dataset. The main dataset set consists of blood pressure measurements for sessions at the health kiosks. The supplemental dataset contains responses on three different surveys users can choose to participate in (ada, bsaa, sleep). There exists a unique `session_id_mask` variable, which in the codebook, represents a "single unique visit or session." However, I noticed one session ID could have multiple rows. These rows tended to differ by `survey_path`. There is also a `captured` variable recording the exact time of measurement. 

I need to think through exactly how to go about cleaning this dataset. Ideally, there should only be one measurement for each `session_id_mask`. The main steps at a high level should be

1. How many sessions have multiple measurements?
2. For sessions with multiple measurements, how are they different? Multiple survey paths? Different timestamps? Different accounts/pseudo members?
3. Are the responses different for the multiple measurements within a session? If the responses are all the same, then just pick one.
4. For sessions with differing responses, which response should we trust, based on the differing variables?

# 2024-06-26

## What to do

- Create a `.csv` of the marginal proportions for age, sex, and race for the county, state, and national according to the ACS 2022.
- Draft an email to Cameron and Lauren on how to treat the supplemental dataset, which has multiple rows per session ID. 
- Verify that the main dataset does not have this issue (multiple blood pressure measurements for the same session ID). 

## What was done

- Saved marginal proportions of race and joint proportions of age/sex at the county, state, and national level. 
- Identified all sessions with multiple measurements recorded at the SAME TIMESTAMP. 

## What do I need to do next?

- Separate sessions into those with 1) one measurement 2) multiple measurements but one response 3) multiple measurements with different responses. 
- The first two are easy to deal with. The last we need to send an email to Pursuant about.

# 2024-06-27

## What to do

- Send the email to Cameron and Lauren about how to deal with the supplemental data
- Write code to clean the session IDs in the supplemental data in both the "yes" and "no" diagnoses. 
- Verify all session IDs overlapping between `high_blood_pressure_diagnosis_yes` and `high_blood_pressure_diagnosis_no` agree on their responses. 

## What was done

I was able to identify all session IDs with multiple measurements and conflicting responses. The range of number of measurements for a session ID with conflicting values for high blood pressure diagnosis was 2 to 3. Each time, the conflicting response was a result of different survey paths. The question now is how to deal with all these different cases. Our final product should just be a dataset with the session ID and the value of the response. A two-column data.table. 

# 2024-06-29

Thanks to Lauren, we have settled the issue with the supplemental data and repeat session IDs. We have decided to take the first recorded measurement for all sessions as representative of that session. For example, if session ID 1 had three responses to the HBP question of yes, no, yes, at times 1pm, 2pm, and 3pm, we would take the "yes" given at 1pm. The HBP diagnoses have now been merged to the main dataset. 

We are almost ready to proceed with the raking step and calculating weights for each individual in the sample. Before that, we need to make sure each recorded measurement is an individual session and not a result of repeated measurements. Users can easily enter their data multiple times in a row or take measurements. How can we detect the same user within a time period? 

I think what we can do is just take the mean SBP and DBP for a given account ID, pseudo member ID, year range, and location. This is a simple way to summarize the blood pressure for each individual. One issue we will need to keep in mind is how to preserve the high blood pressure diagnosis for a given individual. Someone might have 70 recordings of blood pressure measurements, but only respond to the supplemental question of HBP diagnosis in one of them. We do not want that one response to get lost when summarizing the blood pressure measurements. Use a command like `max(hbp_diagnosis, na.rm=TRUE)` when performing the final `group_by` and `summarise` operations. 

I'm running the aggregation now - it will likely take a while, so hopefully finishes by tomorrow and we will have a dataset ready for weighting.

# 2024-07-08

Trying to de-duplicate with the entire parquet dataset has not worked. I'm attempting a simple `group_by` and `summarise` operation but the job keeps crashing even when the allocated RAM is sufficient (100GB+). We will need to chunk the data and merge it again using the RSPH cluster. The de-duplication process is as follows.

The key is to remember the hierarchy of personal identifiers goes `session_id_mask` < `pseudo_member_id` < `account_id_mask` . One account can have multiple pseudo member IDs (as time goes on). 

We will launch an array job with about ~1600 tasks, each corresponding to a unique `state-age_group-gender_year_range` group. Sizes range from 1.2 million rows to 1 row, so might need to do some work to make them more balanced (but it's just a one time thing so maybe not). Below is the task map.

```{r, echo = FALSE}
ct <- data.table::fread("data/counts_for_taskmap.csv")
head(ct)
tail(ct)
```

1. For a single job, filter the whole dataset to its partition (year_range, age_group, state, etc.)
2. Eliminate all duplicate rows (somehow they're in there). Some were introduced by the merging of the urban/rural and HBP diagnosis data. 
3. Verify each row is associated with a unique `session_id_mask`. Repeats are most likley duplicates when it comes to BP measurements. 
4. Once all sessions are unique, for rows with the same `account_id_mask` OR `pseudo_member_id`, take the mean of SBP, the mean of DBP, and the maximum of the HBP diagnosis (within a county & year range). Every row will represent one member-county-year range.   